{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Visualization\n",
    "\n",
    "This notebook reproduces the attention visualization figures:\n",
    "- **Fig 4**: Cross-image attention from keypoints (layer 15)\n",
    "- **Fig S8**: Layer 0 attention (early layer, minimal differentiation)\n",
    "- **Fig S9**: Layer 15 attention (additional trials)\n",
    "\n",
    "**Requires GPU**: This notebook loads VGGT and extracts attention maps.\n",
    "\n",
    "You can either:\n",
    "1. Run `python scripts/run_attention.py --gpu_id <GPU>` first, then load pre-extracted data below\n",
    "2. Or run the live extraction cells directly (requires GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from human_multiview.config import RESULTS_DIR, N_LAYERS\n",
    "from human_multiview.data import load_mochi, get_trial_images\n",
    "from human_multiview.models import get_model\n",
    "from human_multiview.models.base import clear_gpu_memory\n",
    "from human_multiview.attention import (\n",
    "    AttentionExtractor,\n",
    "    extract_attention,\n",
    "    plot_attention_figure,\n",
    ")\n",
    "from human_multiview.plotting import set_paper_style\n",
    "\n",
    "set_paper_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_mochi()\n",
    "print(f\"Loaded {len(dataset)} trials\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "ModelClass = get_model(\"vggt\")\n",
    "vggt = ModelClass()\n",
    "vggt.load(device)\n",
    "\n",
    "extractor = AttentionExtractor(vggt.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define trials and keypoints\n",
    "\n",
    "Edit the cells below to choose which trials and keypoints to visualize.\n",
    "Default examples from the manuscript are pre-filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_trial_by_name(dataset, name):\n",
    "    \"\"\"Find trial index by name.\"\"\"\n",
    "    for i in range(len(dataset)):\n",
    "        if dataset[i][\"trial\"] == name:\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_trials_by_condition(dataset, condition, n=1):\n",
    "    \"\"\"Find trial indices for a given condition.\"\"\"\n",
    "    indices = []\n",
    "    for i in range(len(dataset)):\n",
    "        if dataset[i][\"dataset\"] == condition:\n",
    "            indices.append(i)\n",
    "            if len(indices) >= n:\n",
    "                break\n",
    "    return indices\n",
    "\n",
    "\n",
    "def show_trial(dataset, trial_idx):\n",
    "    \"\"\"Display the three images of a trial.\"\"\"\n",
    "    trial = dataset[trial_idx]\n",
    "    img_A, img_Ap, img_B, info = get_trial_images(trial)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(9, 3))\n",
    "    for ax, img, title in zip(axes, [img_A, img_Ap, img_B], [\"A\", \"A'\", \"B\"]):\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(title, fontsize=14)\n",
    "        ax.axis(\"off\")\n",
    "    fig.suptitle(f\"Trial {trial_idx}: {info['trial_name']} ({info['dataset']})\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return img_A, img_Ap, img_B, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example trials — edit these to explore different trials\n",
    "# Each entry: (trial_index, list of (x, y) keypoints on image A)\n",
    "# Keypoints are in pixel coordinates of the original image.\n",
    "\n",
    "# Find example trials from different conditions\n",
    "shapegen_trials = find_trials_by_condition(dataset, \"shapegen\", n=3)\n",
    "barense_trials = find_trials_by_condition(dataset, \"barense\", n=3)\n",
    "shapenet_trials = find_trials_by_condition(dataset, \"shapenet\", n=3)\n",
    "\n",
    "# Use the first trial from each condition for the main figures\n",
    "trial_configs = []\n",
    "\n",
    "for trial_idx in [shapegen_trials[0], barense_trials[0]]:\n",
    "    trial = dataset[trial_idx]\n",
    "    img_A, img_Ap, img_B, info = get_trial_images(trial)\n",
    "    w, h = img_A.size\n",
    "    # Auto-generate keypoints in a grid over the center of the image\n",
    "    keypoints = [\n",
    "        (int(w * 0.35), int(h * 0.35)),\n",
    "        (int(w * 0.65), int(h * 0.35)),\n",
    "        (int(w * 0.35), int(h * 0.65)),\n",
    "        (int(w * 0.65), int(h * 0.65)),\n",
    "        (int(w * 0.50), int(h * 0.50)),\n",
    "    ]\n",
    "    trial_configs.append((trial_idx, keypoints))\n",
    "    print(f\"Trial {trial_idx}: {info['trial_name']} ({info['dataset']}) — {len(keypoints)} keypoints\")\n",
    "\n",
    "print(f\"\\nTotal: {len(trial_configs)} trial configurations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview trials\n",
    "\n",
    "View the trial images and keypoint locations before extracting attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial_idx, keypoints in trial_configs:\n",
    "    img_A, img_Ap, img_B, info = show_trial(dataset, trial_idx)\n",
    "    print(f\"  Keypoints: {keypoints}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig 4: Cross-image attention (layer 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 15\n",
    "\n",
    "for trial_idx, keypoints in trial_configs:\n",
    "    trial = dataset[trial_idx]\n",
    "    img_A, img_Ap, img_B, info = get_trial_images(trial)\n",
    "\n",
    "    # Extract attention for A→A' pair\n",
    "    attn_maps_Ap, patch_info = extract_attention(\n",
    "        vggt, img_A, img_Ap, extractor, (layer,)\n",
    "    )\n",
    "\n",
    "    # Extract attention for A→B pair\n",
    "    attn_maps_B, _ = extract_attention(\n",
    "        vggt, img_A, img_B, extractor, (layer,)\n",
    "    )\n",
    "\n",
    "    fig = plot_attention_figure(\n",
    "        img_A, img_Ap, img_B, keypoints,\n",
    "        attn_maps_Ap, attn_maps_B, patch_info,\n",
    "        layer=layer, head=\"mean\", sigma=1.0,\n",
    "        include_B=True, mask_attention=True,\n",
    "    )\n",
    "    fig.suptitle(\n",
    "        f\"Fig 4: {info['trial_name']} — Layer {layer}\",\n",
    "        fontsize=14, y=1.02\n",
    "    )\n",
    "    plt.savefig(RESULTS_DIR / f\"fig4_attention_L{layer}_{info['dataset']}_{trial_idx}.pdf\",\n",
    "                bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    del attn_maps_Ap, attn_maps_B\n",
    "    clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig S8: Early layer attention (layer 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 0\n",
    "\n",
    "for trial_idx, keypoints in trial_configs:\n",
    "    trial = dataset[trial_idx]\n",
    "    img_A, img_Ap, img_B, info = get_trial_images(trial)\n",
    "\n",
    "    attn_maps_Ap, patch_info = extract_attention(\n",
    "        vggt, img_A, img_Ap, extractor, (layer,)\n",
    "    )\n",
    "    attn_maps_B, _ = extract_attention(\n",
    "        vggt, img_A, img_B, extractor, (layer,)\n",
    "    )\n",
    "\n",
    "    fig = plot_attention_figure(\n",
    "        img_A, img_Ap, img_B, keypoints,\n",
    "        attn_maps_Ap, attn_maps_B, patch_info,\n",
    "        layer=layer, head=\"mean\", sigma=1.0,\n",
    "        include_B=True, mask_attention=True,\n",
    "    )\n",
    "    fig.suptitle(\n",
    "        f\"Fig S8: {info['trial_name']} — Layer {layer}\",\n",
    "        fontsize=14, y=1.02\n",
    "    )\n",
    "    plt.savefig(RESULTS_DIR / f\"fig_s8_attention_L{layer}_{info['dataset']}_{trial_idx}.pdf\",\n",
    "                bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    del attn_maps_Ap, attn_maps_B\n",
    "    clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig S9: Layer 15 attention (additional trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 15\n",
    "\n",
    "# Additional trials from different conditions\n",
    "extra_indices = []\n",
    "for cond_trials in [shapegen_trials[1:], barense_trials[1:], shapenet_trials[:2]]:\n",
    "    extra_indices.extend(cond_trials)\n",
    "\n",
    "for trial_idx in extra_indices:\n",
    "    trial = dataset[trial_idx]\n",
    "    img_A, img_Ap, img_B, info = get_trial_images(trial)\n",
    "\n",
    "    w, h = img_A.size\n",
    "    keypoints = [\n",
    "        (int(w * 0.35), int(h * 0.35)),\n",
    "        (int(w * 0.65), int(h * 0.35)),\n",
    "        (int(w * 0.35), int(h * 0.65)),\n",
    "        (int(w * 0.65), int(h * 0.65)),\n",
    "        (int(w * 0.50), int(h * 0.50)),\n",
    "    ]\n",
    "\n",
    "    attn_maps_Ap, patch_info = extract_attention(\n",
    "        vggt, img_A, img_Ap, extractor, (layer,)\n",
    "    )\n",
    "    attn_maps_B, _ = extract_attention(\n",
    "        vggt, img_A, img_B, extractor, (layer,)\n",
    "    )\n",
    "\n",
    "    fig = plot_attention_figure(\n",
    "        img_A, img_Ap, img_B, keypoints,\n",
    "        attn_maps_Ap, attn_maps_B, patch_info,\n",
    "        layer=layer, head=\"mean\", sigma=1.0,\n",
    "        include_B=True, mask_attention=True,\n",
    "    )\n",
    "    fig.suptitle(\n",
    "        f\"Fig S9: {info['trial_name']} — Layer {layer}\",\n",
    "        fontsize=14, y=1.02\n",
    "    )\n",
    "    plt.savefig(RESULTS_DIR / f\"fig_s9_attention_L{layer}_{info['dataset']}_{trial_idx}.pdf\",\n",
    "                bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    del attn_maps_Ap, attn_maps_B\n",
    "    clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vggt.unload()\n",
    "print(\"Model unloaded.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}